---
title:  "로드 밸런싱(Load Balancing)"
excerpt: "로드 밸런싱(Load Balancing)을 알아보자!"

categories:
  - IT
  
last_modified_at: 2021-03-08T18:35:00
---

보통 대부분의 인터넷 서비스는 **클라이언트-서버 모델(Client-Server Model)**을 사용한다.  

![로드 밸런싱](https://user-images.githubusercontent.com/53072057/110276109-d324b980-8015-11eb-9d5b-1771575edaf3.JPG)  

예를 들어 하나의 서버가 다수의 클라이언트를 관리하는 1:N 관계를 가진다고 하자. 서버가 맡은 클라이언트의 수가 굉장히 적다면 우리는 트래픽에 대해 아무런 걱정을 할 필요가 없을 것이다. 충분히 서버의 성능으로 모든 클라이언트의 요청을 처리해 줄 수 있기 때문이다.  

![로드 밸런싱1](https://user-images.githubusercontent.com/53072057/110276115-d455e680-8015-11eb-9115-405ffe1c6bc5.JPG)  

그렇다면 클라이언트 수가 굉장히 많다면 어떻게 될까? 서버의 성능은 한계가 존재하기 때문에 결국 클라이언트의 모든 요청을 신속하게 처리해 주기는 불가능할 것이다.  

![로드 밸런싱2](https://user-images.githubusercontent.com/53072057/110276116-d455e680-8015-11eb-972a-b36865192168.JPG)  

이렇게 트래픽이 증가할 경우 어떻게 해결해야 할까? 이는 크게 두 가지 해결 방법이 존재한다.  

![로드 밸런싱3](https://user-images.githubusercontent.com/53072057/110276118-d4ee7d00-8015-11eb-810d-15f188a5dc09.JPG)  

서버 자체 성능을 업그레이드하는 것은 하드웨어이기 때문에 한계가 존재한다. 또한, 하드웨어를 업그레이드하는 비용보다 서버 한 대를 추가하는 비용이 더 저렴하기 때문에 Scale out 방식이 훨씬 효율적이다.  

따라서 Scale out 방식을 더 선호한다. 하지만 다수의 서버를 사용한다고 하여도 트래픽이 한쪽으로만 몰리게 되면 다수의 서버를 사용하는 의미가 사라진다.  

즉, 트래픽이 모든 서버에 골고루 퍼질 수 있도록 해줘야 한다. 이처럼 **여러 대의 서버로 트래픽(Load)을 균등하게 분산(Balancing)해주는 기술을 로드 밸런싱(Load Balancing)**이라고 한다.  

![로드 밸런싱4](https://user-images.githubusercontent.com/53072057/110276119-d4ee7d00-8015-11eb-8624-a96a5119a231.JPG)  

<h2>[ 로드 밸런싱(Load Balancing) ]</h2>  

* 로드 밸런싱은 하나의 서비스를 하나 이상의 노드가 처리하는 식으로 작동한다.  
* 서버의 로드를 클러스터링된 서버별로 균등하게 나누어 주는 서버를 뜻한다.  
* 여러 서버를 통해 운영되기 때문에 한 서버가 다운되더라도 이중화시킨 다른 서버에서 서비스를 지속해주기 때문에 클라이언트는 문제없이 계속해서 서비스를 받을 수 있는 장점이 있다.  
* 로드 밸런싱을 해주는 소프트웨어 or 하드웨어 장비를 로드 밸런서라고 한다.  
* 로드 밸런서의 주 목적은 동시에 오는 수많은 커넥션을 처리하고 해당 커넥션이 요청 노드 중의 하나로 전달될 수 있도록 해주는 것이다.  
* 또한, 단지 노드를 추가하는 것만으로 서비스가 확장성을 가질 수 있는 장점이 있다.  

![로드 밸런싱5](https://user-images.githubusercontent.com/53072057/110276122-d5871380-8015-11eb-9951-e8ca1a3639ff.JPG)  

그렇다면 어떠한 기준으로 트래픽을 각 서버에 배정할까? 이는 다양한 알고리즘들이 존재한다.  

<h2>[ 로드 밸런싱 알고리즘 ]</h2>  

![로드 밸런싱6](https://user-images.githubusercontent.com/53072057/110276124-d61faa00-8015-11eb-8e3d-ea78c722af89.JPG)  

로드 밸런싱은 네트워크 상의 각 계층마다 다양한 종류가 존재한다.  

<h2>[ 로드 밸런싱 종류 ]</h2>  

![로드 밸런싱7](https://user-images.githubusercontent.com/53072057/110276125-d61faa00-8015-11eb-8089-b56e8593ea85.JPG)  

<h2>[ 로드 밸런싱 장애 발생 시 ]</h2>  

로드 밸런싱의 장점 중 하나는 한 서버가 장애가 발생되어도 이중화를 통해 다른 서버에서 서비스를 지속할 수 있다는 것이다.  

만약 A, B 서버가 이중화로 구성되어 있다면 A 서버를 Master 서버라고 하고 B 서버를 Standby 서버로 구성한다.  

평상시에는 Master 서버인 A만 운용되고 Standby 서버인 B는 대기 상태로 있다가 만약, A 서버가 Fail 되었을 시 B 서버가 Master 서버의 역할을 수행한다.  

이 구성을 Fail Over이라고 한다.  

<h2>[ 로드 밸런싱 단점 ]</h2>  

로드 밸런서를 사용할 때 어려운 문제 중 하나는 **세션 데이터를 관리하는 것**이다.  

세션이란 클라이언트의 정보를 저장하는 것인데 로드밸런싱을 통해 하나의 서버에만 저장된다면 다른 서버에서는 세션 정보를 알 수 없기 때문에 세션이 유지되지 않는 단점이 존재한다.  

이를 해결하기 위해 세션을 고정하여 특정 사용자의 요청이 전달될 노드를 고정시킬 수 있다.  

하지만 고정된 세션의 노드에 장애가 발생하면 고정한 의미가 없어지기 때문에 장애가 발생하여 비활성화된 노드에 대한 고려가 필요하다.  

<h2>[ 로드 밸런싱에 사용되는 주요 기술 ]</h2>  

* NAT(Network Address Translation)  
	- private IP를 public IP로 바꾸는데 사용하는 통신망의 주소 변조기  
	
* DSR(Dynamic Source Routing Protocol)  
	- 로드밸런서 사용 시 서버에서 클라이언트로 되돌아가는 경우 목적지 주소를 스위치의 IP 주소가 아닌 클라이언트의 IP 주소로 전달해서 네트워크 스위치를 거치지 않고 바로 클라이언트를 찾아가는 개념  

* Tunneling  
	- 인터넷상에서 눈에 보이지 않는 통로를 만들어 통신할 수 있게 하는 개념  
	

마지막으로 로드 밸런싱과 헷갈리는 개념이 클러스터링이다.  

클러스터링이란 **여러 대의 컴퓨터를 똑같은 구성의 서버 군을 병렬로 연결한 시스템으로 마치 하나의 컴퓨터처럼 사용하는 것을 의미한다.**  

![로드 밸런싱8](https://user-images.githubusercontent.com/53072057/110276126-d6b84080-8015-11eb-90d5-3d0c6ce70520.JPG)  



<h2>[ Reference ]</h2>  
* <https://goodgid.github.io/Load-Balancing-And-Clustering/>  
* <http://www.incodom.kr/Load_Balancing>  
